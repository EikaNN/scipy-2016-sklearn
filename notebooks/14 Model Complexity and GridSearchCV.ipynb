{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andreas Mueller, Kyle Kastner, Sebastian Raschka \n",
      "last updated: 2017-04-11 \n",
      "\n",
      "CPython 3.6.1\n",
      "IPython 5.3.0\n",
      "\n",
      "numpy 1.12.1\n",
      "scipy 0.19.0\n",
      "matplotlib 2.0.0\n",
      "sklearn 0.18.1\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark  -d -u -a 'Andreas Mueller, Kyle Kastner, Sebastian Raschka' -v -p numpy,scipy,matplotlib,sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciPy 2016 Scikit-learn Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter selection, Validation, and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most models have parameters that influence how complex a model they can learn. Remember using `KNeighborsRegressor`.\n",
    "If we change the number of neighbors we consider, we get a smoother and smoother prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/plot_kneigbors_regularization.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above figure, we see fits for three different values of ``n_neighbors``.\n",
    "For ``n_neighbors=2``, the data is overfit, the model is too flexible and can adjust too much to the noise in the training data. For ``n_neighbors=20``, the model is not flexible enough, and can not model the variation in the data appropriately.\n",
    "\n",
    "In the middle, for ``n_neighbors = 5``, we have found a good mid-point. It fits\n",
    "the data fairly well, and does not suffer from the overfit or underfit\n",
    "problems seen in the figures on either side. What we would like is a\n",
    "way to quantitatively identify overfit and underfit, and optimize the\n",
    "hyperparameters (in this case, the polynomial degree d) in order to\n",
    "determine the best algorithm.\n",
    "\n",
    "We trade off remembering too much about the particularities and noise of the training data vs. not modeling enough of the variability. This is a trade-off that needs to be made in basically every machine learning application and is a central concept, called bias-variance-tradeoff or \"overfitting vs underfitting\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/overfitting_underfitting_cartoon.svg\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters, Over-fitting, and Under-fitting\n",
    "\n",
    "Unfortunately, there is no general rule how to find the sweet spot, and so machine learning practitioners have to find the best trade-off of model-complexity and generalization by trying several hyperparameter settings. Hyperparameters are the internal knobs or tuning parameters of a machine learning algorithm (in contrast to model parameters that the algorithm learns from the training data -- for example, the weight coefficients of a linear regression model); the number of *k* in K-nearest neighbors is such a hyperparameter.\n",
    "\n",
    "Most commonly this \"hyperparameter tuning\" is done using a brute force search, for example over multiple values of ``n_neighbors``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 1, average score: 0.543207\n",
      "n_neighbors: 3, average score: 0.714354\n",
      "n_neighbors: 5, average score: 0.704597\n",
      "n_neighbors: 10, average score: 0.687146\n",
      "n_neighbors: 20, average score: 0.642027\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# generate toy dataset:\n",
    "x = np.linspace(-3, 3, 100)\n",
    "rng = np.random.RandomState(42)\n",
    "y = np.sin(4 * x) + x + rng.normal(size=len(x))\n",
    "X = x[:, np.newaxis]\n",
    "\n",
    "cv = KFold(shuffle=True)\n",
    "\n",
    "# for each parameter setting do cross-validation:\n",
    "for n_neighbors in [1, 3, 5, 10, 20]:\n",
    "    scores = cross_val_score(KNeighborsRegressor(n_neighbors=n_neighbors), X, y, cv=cv)\n",
    "    print(\"n_neighbors: %d, average score: %f\" % (n_neighbors, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a function in scikit-learn, called ``validation_plot`` to reproduce the cartoon figure above. It plots one parameter, such as the number of neighbors, against training and validation error (using cross-validation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x10f12c518>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xd8VFXex/HPSSMEEiCFlpBMKNJ7gBSRJhBRQcRFUErU\nld117S6W1XXRfXxWl9W1rOVBFxMQKUtfREUEREyAhB46CZNGS0IJAdLP88cNbMRAysxkkpnf+/Xi\nRWbm5t5zMX65/O6556e01gghhHAsLvYegBBCCOuTcBdCCAck4S6EEA5Iwl0IIRyQhLsQQjggCXch\nhHBAEu5CCOGAJNyFEMIBSbgLIYQDcrPXgf39/bXJZLLX4YUQokHasWNHjtY6oKrt7BbuJpOJpKQk\nex1eCCEaJKVUWnW2k7KMEEI4IAl3IYRwQBLuQgjhgOxWcxdCOIbi4mIyMzMpKCiw91AciqenJ0FB\nQbi7u9fq+yXchRAWyczMxNvbG5PJhFLK3sNxCFprcnNzyczMJDQ0tFb7qLIso5Saq5Q6o5RKvsHn\nSin1vlLqmFJqr1KqX61GIoRokAoKCvDz85NgtyKlFH5+fhb9a6g6NfdYIPomn98BdCr/NQP4uNaj\nEUI0SBLs1mfpn2mV4a613gycvckm44B52rAVaK6UamPRqG5iR9pZ3vrmENIeUAghbswas2UCgYwK\nrzPL3/sFpdQMpVSSUiopOzu7VgfbfyKPjzelkHnuSq2+XwjhWM6fP89HH31Uq+8dM2YM58+ft/KI\n6oc6nQqptZ6jtQ7TWocFBFT59Gylwtv7AZCQkmvNoQkhGqibhXtJSclNv3ft2rU0b97cquO5/phV\njaGm21WXNcI9C2hX4XVQ+Xs20allU/yberA1VcJdCAEvvvgiKSkp9OnTh5kzZ7Jp0yYGDx7M2LFj\n6datGwD33HMP/fv3p3v37syZM+fa95pMJnJycjCbzXTt2pVHH32U7t27M2rUKK5c+WV1IDs7mwkT\nJjBgwAAGDBjATz/9BMCsWbOYOnUqUVFRTJ06ldjYWMaOHcvw4cMZMWIEWmtmzpxJjx496NmzJ4sX\nLwaodKzWYo2pkKuBx5VSi4BBwAWt9Ukr7LdSSikGtfcjITUXrbXcyBGiHnntP/s5cCLPqvvs1taH\nP9/d/Yafv/nmmyQnJ7N7927ACMydO3eSnJx8bRrh3Llz8fX15cqVKwwYMIAJEybg5+f3s/0cPXqU\nhQsX8umnnzJx4kSWLVvGlClTfrbNU089xTPPPMOtt95Keno6o0eP5uDBgwAcOHCALVu20LhxY2Jj\nY9m5cyd79+7F19eXZcuWsXv3bvbs2UNOTg4DBgzgtttuA/jFWK2lynBXSi0EhgL+SqlM4M+AO4DW\n+hNgLTAGOAZcBh6y6ggrEd7ej6/2niQt9zIm/ya2PpwQooEZOHDgz8Ly/fffZ8WKFQBkZGRw9OjR\nX4R7aGgoffr0AaB///6YzeZf7Hf9+vUcOHDg2uu8vDzy8/MBGDt2LI0bN7722ciRI/H19QVgy5Yt\nTJ48GVdXV1q1asWQIUNITEzEx8fnF2O1lirDXWs9uYrPNfB7q42oGiLK6+5bU3Ml3IWoR252hV2X\nmjT5by5s2rSJ9evXk5CQgJeXF0OHDq10/nijRo2ufe3q6lppWaasrIytW7fi6el502NW9ro6Y7Wm\nBrm2TIeAJgR4NyJB6u5COD1vb28uXrx4w88vXLhAixYt8PLy4tChQ2zdurXWxxo1ahQffPDBtddX\nS0FVGTx4MIsXL6a0tJTs7Gw2b97MwIEDaz2O6miQ4a6UIry9H1vL6+5CCOfl5+dHVFQUPXr0YObM\nmb/4PDo6mpKSErp27cqLL75IeHh4rY/1/vvvk5SURK9evejWrRuffPJJtb5v/Pjx9OrVi969ezN8\n+HD+9re/0bp161qPozqUvcIxLCxMW9KsY8G2NF5ekcyG54bQPqCpFUcmhKiJgwcP0rVrV3sPwyFV\n9merlNqhtQ6r6nsb5JU7VKy73+zhWSGEcE4NNtxD/ZvQykfq7kIIUZkGG+5X6+4JKVJ3F0KI6zXY\ncAejNJOTX0hK9iV7D0UIIeqVBh3u19aZkdKMEEL8TIMO9xA/L9o085R1ZoQQ4joNOtyv1t23yXx3\nIZyWJUv+Arz77rtcvnzZiiOqHxp0uMPVunsRx87k23soQgg7sHe415clfq/X4BtkR3T4b929Uytv\nO49GCFHXKi75O3LkSGbPns3s2bNZsmQJhYWFjB8/ntdee41Lly4xceJEMjMzKS0t5U9/+hOnT5/m\nxIkTDBs2DH9/fzZu3Pizfe/YsYNnn32W/Px8/P39iY2NpU2bNgwdOpQ+ffpcWxBs3759eHp6smvX\nLqKionjllVd4+OGHSU1NxcvLizlz5tCrVy9mzZpFSkoKqampBAcHs3DhQpv9uTT4cA9q0ZjA5o1J\nSMllWoTJ3sMRwrl9/SKc2mfdfbbuCXe8ecOPr1/yd926dRw9epTt27ejtWbs2LFs3ryZ7Oxs2rZt\ny1dffQUYa840a9aMd955h40bN+Lv7/+z/RYXF/PEE0+watUqAgICWLx4MS+//DJz584FoKioiKtP\n2cfExJCZmUl8fDyurq488cQT9O3bl5UrV7JhwwamTZt2bXwVlwa2pQYf7lfr7hsPn6GsTOPiIuu7\nC+HM1q1bx7p16+jbty8A+fn5HD16lMGDB/Pcc8/xwgsvcNdddzF48OCb7ufw4cMkJyczcuRIAEpL\nS2nT5r/toe+///6fbf+rX/0KV1dXwFjid9myZQAMHz6c3Nxc8vKMde6vXxrYVhp8uAOEt/dl2c5M\njpy5SJfWPvYejhDO6yZX2HVFa81LL73Eb37zm198tnPnTtauXcsrr7zCiBEjePXVV2+6n+7du5OQ\nkFDp5/Vtid/rNfgbqvDf+e5bpa+qEE7n+iV/R48ezdy5c6810cjKyuLMmTOcOHECLy8vpkyZwsyZ\nM9m5c2el339V586dyc7OvhbuxcXF7N+/v1pjGjx4MAsWLACM9eT9/f3x8anbC0+HuHJv5+tFUIvG\nJKTmEhNl/Y4mQoj6q+KSv3fccQezZ8/m4MGDREREANC0aVO++OILjh07xsyZM3FxccHd3Z2PP/4Y\ngBkzZhAdHU3btm1/dkPVw8ODpUuX8uSTT3LhwgVKSkp4+umn6d696oYks2bN4uGHH6ZXr154eXkR\nFxdnm5O/iQa75O/1Zv57D98dPM3OV0ZK3V2IOiRL/tqOUy75e72IDn6cv1zMoVM37sgihBDOwmHC\nXdaZEUKI/3KYcG/bvDEhfl6yzowQdiDLf1ifpX+mDhPuAOGhxjozpWXygyZEXfH09CQ3V9Z3siat\nNbm5uXh6etZ6Hw4xW+aqiA5+LE7K4ODJPHoENrP3cIRwCkFBQWRmZpKdnW3voTgUT09PgoKCav39\nDhXu1+a7p+ZKuAtRR9zd3QkNlSnI9U21yjJKqWil1GGl1DGl1IuVfB6ilPpeKbVXKbVJKVX7v24s\n0LqZJ6H+TaTuLoRwelWGu1LKFfgQuAPoBkxWSnW7brO/A/O01r2A14G/Wnug1RXe3o9tx89K3V0I\n4dSqc+U+EDimtU7VWhcBi4Bx123TDdhQ/vXGSj6vM+HtfblYUML+ExfsNQQhhLC76oR7IJBR4XVm\n+XsV7QHuLf96POCtlPKzfHg1F1Gh7i6EEM7KWlMh/wAMUUrtAoYAWUDp9RsppWYopZKUUkm2urPe\n0seT9gFNSJBFxIQQTqw64Z4FtKvwOqj8vWu01ie01vdqrfsCL5e/d/76HWmt52itw7TWYQEBARYM\n++Yi2vuRaD5HSWmZzY4hhBD1WXXCPRHopJQKVUp5AJOA1RU3UEr5K6Wu7uslYK51h1kz4e39yC8s\nIflEnj2HIYQQdlNluGutS4DHgW+Bg8ASrfV+pdTrSqmx5ZsNBQ4rpY4ArYA3bDTeagmXursQwslV\n6yEmrfVaYO11771a4eulwFLrDq32Arwb0allUxJScvntkA72Ho4QQtQ5h1pbpqLw9n4kms9SLHV3\nIYQTcthwj+jgx+WiUvZlyXx3IYTzcdhwHxTqCyBTIoUQTslhw92vaSM6t/KWm6pCCKfksOEOxlIE\nSeZzFJVI3V0I4VwcOtwjOvhxpbiUfVm/eJ5KCCEcmkOH+6DQ8r6qUncXQjgZhw73Fk086NLaW5pm\nCyGcjkOHOxilmR1p5ygs+cU6ZkII4bAcPtzD2/tRUFzGngyZ7y6EcB6OH+6hfjRyc+HJhbtYuiOT\nMunQJIRwAg4f7s283Pny0XBaNfPkD//ew10fbCH+WI69hyWEEDbl8OEO0D+kBSt+F8l7k/pw4Uox\nD3y2jYdjEzl25qK9hyaEEDbhFOEO4OKiGNcnkO+fG8KLd3Qh8fhZRr/7I6+s3EdOfqG9hyeEEFbl\nNOF+lae7K78d0oEfnh/GlEHBLNyewdDZm/hw4zEKimVGjRDCMThduF/l28SD18b1YN0ztxHRwY/Z\n3x5m+N83sWKX3HQVQjR8ThvuV3UIaMqn08JY+Gg4vk09eGbxHsZ9+JM81SqEaNCcPtyviujgx+rf\n38o/7u9NTn4hkz/dyrS520mW9eCFEA2Q0to+JYiwsDCdlJRkl2NXpaC4lHkJZj7alML5y8Xc2bMN\nz466hQ4BTe09NCGEk1NK7dBah1W5nYT7jeUVFPPZ5lQ+23KcwpIy7usXxFO3d6Jt88b2HpoQwklJ\nuFtRTn4hH248xoKt6aBgangIjw3tgF/TRvYemhDCyUi420Dmucu8t/4oy3Zm0tjdlV8Pbs+vB4fi\n7elu76EJIZyEhLsNHTtzkbfXHeHr5FO08HLn98M6MiU8BE93V3sPTQjh4CTc68DezPPM/vYwPx7N\noU0zT54a0Yn7+gfh5iqTkIQQtlHdcJcUskCvoObMf2QQXz46iFY+nry4fB+j/rGZNXtPyINQQgi7\nqla4K6WilVKHlVLHlFIvVvJ5sFJqo1Jql1Jqr1JqjPWHWn9FdvBnxWORzJnaHzdXxeNf7uLuf25h\n0+Ez2OtfRkII51ZlWUYp5QocAUYCmUAiMFlrfaDCNnOAXVrrj5VS3YC1WmvTzfbrCGWZypSWaVbt\nzuKd746Qee4KA0N9eSG6M/1DfO09NCGEA7BmWWYgcExrnaq1LgIWAeOu20YDPuVfNwNO1GSwjsTV\nRXFvvyA2PDeU18d1JzX7EhM+TuCR2EQOnsyz9/CEEE6iOuEeCGRUeJ1Z/l5Fs4ApSqlMYC3wRGU7\nUkrNUEolKaWSsrOzazHchsPDzYVpESY2Pz+UmaM7k2g+y5j3f+SpRbtIy71k7+EJIRyctW6oTgZi\ntdZBwBhgvlLqF/vWWs/RWodprcMCAgKsdOj6zcvDjd8P68iPzw/nt0M68O3+U4x4+wdeXrGP03kF\n9h6eEMJBVSfcs4B2FV4Hlb9X0SPAEgCtdQLgCfhbY4COopmXOy9Ed2HzzGFMHhjM4sQMhszeyF+/\nPsj5y0X2Hp4QwsFUJ9wTgU5KqVCllAcwCVh93TbpwAgApVRXjHB37LpLLbX08eQv9/Rgw3NDuaNH\nG+ZsTmXw3zbyzw1HuVRYYu/hCSEcRLUeYiqf2vgu4ArM1Vq/oZR6HUjSWq8unyHzKdAU4+bq81rr\ndTfbp6POlqmpQ6fy+Pu3R1h/8DT+TT14fFhHJg8KppGbPO0qhPgleUK1gdmRdo7Z3x5ia+pZgn29\neGN8DwZ3co77EkKI6pMnVBuY/iEtWPhoOHEPD8TNRTH1X9t5bskezl2SerwQouYk3OsRpRRDbglg\n7VODeXxYR1btzuL2d35g9Z4T8qSrEKJGJNzrIU93V/4wujP/eeJWglo05smFu3gkLoms81fsPTQh\nRAMh4V6PdW3jw/LHovjTXd1ISMll1Ds/EPvTcUplUTIhRBUk3Cuz5V2YPx72LIKiy3YdiquL4pFb\nQ1n3zG2EmXyZ9Z8D3PdJPIdPXbTruIQQ9ZvMlrneT+/Bd6+CZ3MoOA+NfKDnfdB3KrTtC0rZbWha\na1bvOcFr/znAxYJifjekA78f3lGmTQrhRGQqZG1s/xTW/gF6TIDxcyBjK+ycDwdWQckVaNUD+k6B\nXveDl/1WeTx7qYj/WXOA5buy6BDQhDcn9GKASVadFMIZSLjX1K4FsOox6HwnTIwD1wp9UQsuwL6l\nsGs+nNgFrh7Q5U7jar79MHCxT3XrhyPZ/HH5PrLOX2FKeDDPR3fBR/q5CuHQJNxrInkZLPs1tB8K\nkxeBW6Mbb3sq2Qj5vYvhyjlo1g76PAh9H4TmwXU14msuFZbwzndH+Pyn47T09uT1cd0Z1b11nY9D\nCFE3JNyr6/DXsHgKBA2EKcvAw6t631dSCIfWGGWb1E3Ge+2HGFfzXe4Cd0+bDbkyezLO88KyvRw6\ndZExPVsza2x3WnrX7RiEELYn4V4dKRvgy/uhdU+YuhI8far+nsqcT4fdXxqlnQvp0LgF9JwI/aYa\n+64jxaVlzNmcynvfH8XTzYWX7+zKxLB2KDveBBZCWJeEe1XS4mH+veDXAab/xzo3SMvK4Pgm42r+\n0BooLYI2fYyQ73EfNG5u+TGqITU7n5eW72Pb8bOEt/flr/f2ItS/SZ0cWwhhWxLuN5O5A+aNA582\nELMWmtpgga7LZ2HvEqM+fzoZ3Dyh2zhjtk3IrTa/CVtWplmclMH/rj1IYUkZT9/eiUcHt8fdVR5t\nEKIhk3C/kVPJEHuncRX90Nfg09a2x9PamGGza74x46YwD1qYjJDv86DNj38mr4A/r97P18mn6NrG\nh7cm9KRXUN38C0IIYX0S7pXJPgKxY4ypjA99DS1C6vb4RZfh4GrY9QWYfwTlAh1vN27C3hINbh42\nO/S3+0/x6qpksi8W8nBUKM+OugUvDzebHU8IYRsS7tc7Z4a5d0BZsRHs/p3q7tiVyU2B3QuMG7EX\nT4KXP/SeBP2mQUBnmxwyr6CYt74+xIJt6QS1aMz/ju/JbbfImvFCNCQS7hVdyILPo6HwIsR8Ba26\n181xq6O0BFK+h53z4Mg3UFYCwZEw/GUw3WqTQ24/fpYXl+8lNfsS9/YL5E93dqNFE9v9q0EIYT0S\n7leVlsAnUZB3AqatgsB+tj9mbeWfMRYr2/qRcTXfYQSMeBXa9rH6oQqKS/lw4zE+3pSCT2N3/nx3\nN8b2bivTJoWo56QT01UndkL2IRgzu34HO0DTlhD1JDy5C0b+xRj7nCGwZDrkHLXqoTzdXXluVGfW\nPHkrwb5ePLVoNw/FJpJ5zr6rYAohrMPxwz1lA6Cg0yh7j6T63BsbIf/UHrjteTj6HXw4CFY9Dhcy\nrXqoLq19WPa7SP58dze2Hz/LqH9sZu4WWTNeiIbO8csy/xptPEw0Y6Ptj2Ur+dnw49uQ9C/j9YBH\nYfCz0MTfqofJPHeZV1Yms+lwNr3bNeetCT3p0rqWT+0KIWxCyjJgrOaYmQgdhtl7JJZpGgB3vAlP\n7DCWNdj2MbzXGzb+FQryrHaYoBZefB4zgPcm9SHj7GXuen8Lb687TEFxqdWOIYSoG44d7uYtoEuh\nw3B7j8Q6mgfDPR/CY1uNc/rhTSPk4z+AYuv0V1VKMa5PIOufHcLYPm35YMMxxrz/I9uPn7XK/oUQ\ndcOxwz1lA7g3MVZ8dCQBneH++fDoRmMmzbpX4P1+sCPWmB1kBb5NPHhnYh/mPTyQopIyJv5fAn9c\nsY+8gmKr7F8IYVvVCnelVLRS6rBS6phS6sVKPv+HUmp3+a8jSqnz1h9qLaRsNOaK2/DJT7sK7AdT\nV8D0NdAsEP7zFHw40FifvqzMKoe47ZYA1j1zG48ODmXR9nRGvvMD3ySfssq+hRC2U2W4K6VcgQ+B\nO4BuwGSlVLeK22itn9Fa99Fa9wE+AJbbYrA1ci4NzqY0/Hp7dYQOhke+g0kLjUYjSx82plAe/c5Y\n28ZCXh5uvHxnN1b+PgrfJo347Rc7+O38HZzOK7DC4IUQtlCdK/eBwDGtdarWughYBIy7yfaTgYXW\nGJxFUstnxzhKvb0qSkGXMfDbLUb/14ILsOA++HwMpG+1yiF6BTVn9eNRPB/dmQ2Hz3D7Oz+wcHs6\nZTJtUoh6pzrhHghkVHidWf7eLyilQoBQYIPlQ7NQygbwbgv+t9h7JHXLxRV63w+PJ8GYvxv/epk7\nGhZMhFP7LN69u6sLjw3tyLdP30b3tj68tHwfkz/dSmp2vhUGL4SwFmvfUJ0ELNVaVzp3Tik1QymV\npJRKys7OtvKhKygrhdQfjJKMsz5O7+YBAx81nnYd8WfI2Aqf3ApLHzEWLbNQqH8TFj4azlsTenLg\nZB7R7/3IhxuPUVxqnVq/EMIy1Qn3LKBdhddB5e9VZhI3KcloredorcO01mEBATZcjfDEbig47zwl\nmZvxaGI88PTUHrj1WTi81rjp+p+njfV2LKCU4v4BwXz/7BBu79qS2d8e5u4PtrAno37cTxfCmVUn\n3BOBTkqpUKWUB0aAr75+I6VUF6AFkGDdIdZCanlVKHSIfcdRnzRuAbf/GZ7cDf0fMtaUf78vrPuT\n0TXKAi19PPnowf7Mmdqfc5eLGP/RT/xlzQEuF1lnWqYQouaqDHetdQnwOPAtcBBYorXer5R6XSk1\ntsKmk4BF2l7rGVSUsgla97JN+7yGzrsV3Pl3eCIJut1jPAD1Xm/4YTYUWlY3H9W9Nd89O4QHBgXz\nry3HGfWPzfxwxIblNyHEDTne2jKF+fCWCSIeg5GvW3//jub0AdjwP3D4K2gSAIP/AGEPGVMqLZBo\nPsuLy/aSkn2J8X0D+dNd3fCVNeOFsJjzri2T9pPRbUnq7dXTqhtM/hIeWQ8BXeCbF+CD/kbZxoKn\nXQeYfPnqycE8Obwja/ae4PZ3fmDlrizqwz/shHAGjhfuKRvAzRPahdt7JA1LuwEw/T8wdaWx2uSq\n38PHEXBgVa0fhPJ0d+XZUZ1Z88Rggn29eHrxbqZ/nkjGWVkzXghbc8Bw3wghUeDuae+RNDxKGdNH\nH90IE+cDCpZMg0+HGX9p1jLkO7f2ZtnvIpl1dzeSzMaa8f+SNeOFsCnHCvcLWZBz2DmWHLAlpaDb\nWPhdPIz7CC7lwPzxEHc3ZNbuPomriyImKpTvnh1CeHtf/rLmAPd+9BMHT1pvyWIhxH85Vrg725ID\ntubqBn0fNNaRj34LzhyEz0bAwgeMG7G1ENi8MXPL14zPPHeFuz/Ywt+/lTXjhbA2xwr3lA3QtBW0\n7Fb1tqL63BpB+G+NB6GGvQLmH+HjSFj+GzhnrvHuKq4ZP65PIP/ceIwx7/1IfEqO9ccuhJNynHAv\nK4PUTdDeiZccsLVGTWHITCPkI5+AAyvhgzD46g9w8XSNd9eiiQdvT+zN/EcGUlxWxgOfbmP8Rz+x\nancWRSWyjIEQlnCcee4ndhvL3I7/P+g9yXr7FTeWdwJ++BvsnGdc3Q/6rdHYu3GLGu/qSlEpixLT\nmZeQxvGcSwR4N+LBQcE8MCiYlt5yc1yIq6o7z91xwn3LP2D9LHjuMHi3tt5+RdVyU2Dj/0LyUvBs\nBlFPw6DfGOva1FBZmWbz0Wxi481sOpyNu6tiTM82xESa6Btc8780hHA0zhfucXfDpVx4LN56+xQ1\nc2offP8XOPqtce/jtpnQb3qtO2GlZuczLyGNpTsyyS8soXdQM6ZHmrizVxsaublaefBCNAzOFe5F\nl+GtEBg4A0a/YZ19itpL3wrrX4P0eGgeAsP+CD1/Zaw1Xwv5hSUs35lJbLyZ1OxL+Df14IGBwTwY\nHkIrHynZCOfiXOF+dD0smABTlkHH262zT2EZreHYevj+NeOKvmU3GP4KdB5T6xveZWWaLcdyiIs3\ns+HwGVyVIrpHax6KMtEvuAVKbqQLJ1DdcHeri8HYXOpGcPWA4Eh7j0RcpRR0GgkdRhizaja+AYse\ngKABMOJVCL2txrt0cVHcdksAt90SQFruJeYlpLEkKYM1e0/SI9CH6REm7u7dFk93KdkI4RhX7h9F\nGCsaTv/FMvOivigtgd0L4Ie3IC/LmLI64lUI7GfRbi8VlrBiVxZx8WaOnsnHt4kHkwe2Y0p4CG2a\nNbbS4IWoP5ynLHPxFLzdGW6fBbc+Y/n+hG0VF0DiZ/Dj23DlLHQdC8P/BAGW9brVWhOfkktsvJn1\nB0/johTR3VszPdLEAJOUbITjcJ6yTOom43dZcqBhcPeEyMeh3zRI+BAS/gmH1kDvB2Doi9C8XdX7\nqIRSiqiO/kR19Cfj7GXmb01j0fZ0vtp3kq5tfIiJDGFcn0Ap2Qin0fCv3JfPgGPfwx+OgovjPHDr\nNC7lwI/vGFfzutS44Rr2sNEi0cL/nleKSlm5O4vYn8wcPn2R5l7uTBoQzNSIEAKbS8lGNEzOUZbR\nGv5+i3Fz7r5/WWdgwj4uZMLWj426/JVz0CIU+sdA3ynG+vIW0FqzNfUscfFm1h04BcCobkbJJry9\nr5RsRIPiHOF+Khk+iYJxHxohIBq+4gI4uBqS5kJ6gjELquvdxtV8SJTF6wZlnrvMF1vTWZSYzvnL\nxXRp7c20CBPj+wbS2ENKNqL+c45wj/8A1r0CzxyAZoHWGZioP84chKTPYc8iKLwA/rcYV/O9J4OX\nr0W7LiguZfXuE3web+bgyTyaNXbn/gHtmBoeQjtfL+uMXwgbcI5wnz/eaNDx+HbrDErUT0WXYf8K\n42o+KwlcG0H38cbVfLuBFl3Na61JNJ8jLt7MN/tPobVmRNdWxESaiOzgJyUbUe84frgXFxhLDvSP\ngTvestq4RD13ap9xNb93CRRdNJ58DXsYek00Fi2zwInzV1iwLY2F2zM4e6mITi2bMj3SxL39AvHy\naPgTy4RjcPxwT9kI8++BB5bALaOtNzDRMBTmG6tQJs2Fk3vA3Qt63GsEfdt+Fl3NFxSXsmbvSWLj\nj5OclYe3pxsTw9oxLSKEEL+ar3QphDU5frh/9yokfAQvmI0mEsJ5Ze2EHZ/DvqVQfBla94Kwh4zF\nyhp513q3Wmt2pp8jNj6Nr/edpFRrhnduyfRIE4M7+UvJRtiF44f7J7dCo2bw0FfWG5Ro2AouGOWa\npM/hzH5ZVgkbAAASU0lEQVTwaGoEfNhD0Ka3Rbs+nVfAgq1pfLk9nZz8ItoHNCEm0sS9/YJo2khK\nNqLuWDXclVLRwHuAK/CZ1vrNSraZCMwCNLBHa/3AzfZpUbjnZ8PfOxqrDN42s3b7EI5La8hMNEJ+\n/3IoKYDA/tD/IaN0U4smIlcVlpTy1d6TxMWb2ZN5Ae9GbkzoH8T0SBOh/lKyEbZntXBXSrkCR4CR\nQCaQCEzWWh+osE0nYAkwXGt9TinVUmt95mb7tSjc9/4blv8aHt1g/E8rxI1cOWdMpUz6HHIOG//a\n632/EfStLGukviv9HLHxZtbuO0lxqWZo5wCmR5oY0ikAFxcp2QjbsGa4RwCztNajy1+/BKC1/muF\nbf4GHNFaf1bdAVoU7isfg0NfwfOptW4AIZyM1pAWb9TmD6yC0iJoF26UbLqNA/faL0dw5mIBX25L\nZ8G2dLIvFhLq34RpESHc1z8Ib093K56EENYN9/uAaK31r8tfTwUGaa0fr7DNSoyr+yiM0s0srfU3\nlexrBjADIDg4uH9aWlr1z+gqreGdrtBuEEyMq/n3C3Ep11jmYEcsnE0Bz+bQ50FjWq0Fq1MWlZTx\ndfJJYuPN7Eo/TxMPVyb0D2JahImOLeWmv7COug73NUAxMBEIAjYDPbXW52+031pfuZ85BB8Ngrvf\nM/5nFKK2ysrA/KMxnfLQGigrAdNg4+eq693g1qjWu96TcZ64eDNr9p6kqLSMwZ38iYk0MaxzSynZ\nCItYc8nfLKDiOqxB5e9VlAls01oXA8eVUkeAThj1eetK2WD83n6Y1XctnIyLC7QfYvy6eBp2f2Fc\nzS97BLz8jPWK+seAb/sa77p3u+a8c38f/nhnVxZuS+eLbWk8EpdEiJ8XU8ND+FVYO5o1lpKNsJ3q\nXLm7YZRcRmCEeiLwgNZ6f4VtojFusk5XSvkDu4A+WuvcG+231lfuJ/dCyvfSmEPYRlmZcQGx43M4\n/LWxDHH7ocbDUZ3HgGvtArm4tIxvkk8RF28mKe0cXh6u3NsvkOkRJjq1qv1cfOF8rD0VcgzwLkY9\nfa7W+g2l1OtAktZ6tTKe5ngbiAZKgTe01otutk+rttkTwhbyTsDO+bAzzmgN2LQV9J0K/adD8+Ba\n7zY56wKx8WZW7zlBUUkZUR39mB5hYkTXVrhKyUZUwfEfYhKirpSWwLHvjOmUR9cZ73UaaUyn7DQK\nXGv3EFNufiGLEjP4YmsaJy8UENSiMdMiQrg/LJhmXlKyEZWTcBfCFs6nw855xhV9/inwCTRaBvad\nWutlp0tKy1h34DSx8Wa2Hz9LY3dX7ukbSEykic6tpWQjfk7CXQhbKi2GI98YM21SNoBygVvuMObN\ndxhe6+cvDpzIIy7ezMrdWRSWlBHe3peYSBO3d22Fm6u0kRQS7kLUnbPHjbr8zvlwOQeaBRt1+b5T\nwbtVrXZ57lLRtZJN1vkrBDZvzJTwECYNaEeLJh5WPgHRkEi4C1HXSoqM+fJJc4358y5uFjf8Likt\nY/3BM8TFm0lIzaWRmwv39AlkeqSJbm19bHASor6TcBfCnnKOGdMprdjw+9CpPOLi01ixK5OC4jIG\nmnyJiTIxqpuUbJyJhLsQ9YENGn6fv1zEkqQM5iWkkXnuCm2aeV4r2fg1rf1TtaJhkHAXor6xcsPv\n0jLNhkNGyWbLsRw83FwY27stMZEmegRa1nJQ1F8S7kLUVzds+P2QsSBeLa7mj56+SFyCmeU7s7hc\nVEr/kBbERJqI7tEadynZOBQJdyEagsoafvd/yFhzvhYNvy9cKebf5SWb9LOXaeXTiAcHhTB5YDAB\n3lKycQQS7kI0JDdq+N3/YQisecPvsjLNpiNn+PwnMz8ezcHD1YW7erVheqSJ3u2a2+gkRF2QcBei\nobJyw++U7HzmxZtZuiOTS0Wl9A1uTkykiTt6tMHDTUo2DY2EuxANnZUbfl8sKGbpjkzmJaRxPOcS\nAd6NeHBQMA8MCqalt6cNTkDYgoS7EI7Cyg2/y8o0m49mExtvZtPhbNxdFWN6tiEm0kTf4BY2Oglh\nLRLuQjgiKzf8Pp5ziXkJZv6dlEl+YQm9g5oxPdLEnb3a0MhN+hPXRxLuQjgyKzf8zi8sYfnOTOLi\nzaRkX8K/qQcPDAzmwfAQWvlIyaY+kXAXwllYseG31potx3KI/cnMhsNncFWK6B6teSjKRL/gFqha\nzMEX1iXhLoSzsXLD77TcS8xPSGNxUgYXC0roEejD9AgTd/dui6e7lGzsRcJdCGdWseH3+XSLGn5f\nKixhxa4s4uLNHD2Tj28TDyYPbMeU8BDaNKtZ+UdYTsJdCGHVht9aaxJScvk83sz6g6dxUYrR3VsR\nExnKAJOUbOqKhLsQ4ues2PA74+xl5m9NY3FiBheuFNO1jQ8xkSGM6xMoJRsbk3AXQlSusobfHW83\nruZr2PD7SlEpK3cbJZtDpy7S3MudSQOCmRoRQmBzKdnYgoS7EKJq1zf89m5rNPzuN61GDb+11mw7\nfpbYn8ysO3AKgFHdWjM90kR4e18p2ViRhLsQovoqbfgdbVzN17Dhd+a5y3yxNZ1Fiemcv1xMl9be\nTIswMb5vII09pGRjKQl3IUTtWKnhd0FxKat3n+DzeDMHT+bRrLE79w9ox9TwENr5etnwBBybVcNd\nKRUNvAe4Ap9prd+87vMYYDaQVf7WP7XWn91snxLuQtRzVmr4rbUm0XyOuHgz3+w/hdaaEV1bERNp\nIrKDn5Rsashq4a6UcgWOACOBTCARmKy1PlBhmxggTGv9eHUHKOEuRANipYbfJy9c4YutaSzcnsHZ\nS0V0atmUaZEm7u0bSJNG1b+R68ysGe4RwCyt9ejy1y8BaK3/WmGbGCTchXB8Vmr4XVBcypq9J4mN\nP05yVh7enm5MDGvHtIgQQvxqtsqls7FmuN8HRGutf13+eiowqGKQl4f7X4FsjKv8Z7TWGTfbr4S7\nEA2cFRp+a63ZmX6O2Pg0vt53klKtGd65JdMjTQzu5C8lm0rUdbj7Afla60Kl1G+A+7XWwyvZ1wxg\nBkBwcHD/tLS0mpyTEKI+slLD79N5BSzYmsaX29PJyS+ifUATYiJN3NsviKZSsrmmTssy123vCpzV\nWt+0u69cuQvhgKzQ8LuwpJS1+04S+5OZPZkX8G7kxoT+QUyPNBHqLyUba4a7G0apZQTGbJhE4AGt\n9f4K27TRWp8s/3o88ILWOvxm+5VwF8KBWanh9650Y5bNV/tOUlyqGdo5gOmRJoZ0CsDFxTlLNtae\nCjkGeBdjKuRcrfUbSqnXgSSt9Wql1F+BsUAJcBb4ndb60M32KeEuhJOwQsPvMxcL+HJbOgu2pZN9\nsZBQ/yZMiwjhvv5BeHtWf/EzRyAPMQkh6hcrNPwuKinj6+STxMab2ZV+niYerkzoH8S0CBMdWza1\n8QnUDxLuQoj6yUoNv/dmnic23syaPScpKi1jcCd/YiJNDOvc0qFLNhLuQoj6zwoNv3PyC1m4LZ0v\ntqVxOq+QED8vpoaH8KuwdjRr7HglGwl3IUTDYYWG38WlZXyTfIq4eDNJaefw8nBlfN9AYiJNdGpV\nvdp+QyDhLoRomK41/P4czqbWquF3ctYF4uLNrNpzgqKSMqI6+jE9wsSIrq1wbeAlGwl3IUTDVlYG\n5s1GyaaWDb9z8wtZlJjBF1vTOHmhgKAWjZkWEcL9YcE082qYJRsJdyGE47Cw4XdJaRnrDpwmNt7M\n9uNn8XR3YXzfIGIiTXRu3bBKNhLuQgjHY4WG3wdO5BEXb2bl7iwKS8oIb+9LTKSJ27u2ws21essY\n25OEuxDCsVnY8PvcpSIWJ2UwPyGNrPNXCGzemCnhIUwa0I4WTTzq4ARqR8JdCOEcLGz4XVJaxvqD\nZ4iLN5OQmksjNxfu6RPI9EgT3dr61MEJ1IyEuxDC+VjY8PvQqTzi4tNYsSuTguIyBpp8mR5pYnT3\n+lOykXAXQjgvCxt+X7hczJKkDOISzGSeu0KbZp7XSjZ+TauepWNLEu5CCAE3aPg9rbzhd+ubfmtp\nmWbDIaNks+VYDh5uLozt3ZaYSBM9Aqu3hLG1SbgLIURFFjb8Pnr6InEJZpbvzOJyUSn9Q1oQE2ki\nukdr3OuwZCPhLoQQN2JBw+8LV4r5d1IG87emkZZ7mVY+jXhwUAiTBwYT4G37ko2EuxBCVMWCht9l\nZZpNR84QG5/G5iPZeLi6cFevNkyPNNG7XXObDVnCXQghasKCht8p2fnMizezdEcml4pK6dOuOQ9F\nmbijRxs83KxbspFwF0KI2rCg4ffFgmKW7shkXkIax3MuEeDdiAcGBvPgoGBa+nhaZXgS7kIIYala\nNvwuK9NsPppNXLyZjYezcXdVjOnZhphIE32DW1g0JAl3IYSwFgsafh/PucS8BDNLkzK5WFhC76Bm\nPB/dhaiON79xeyMS7kIIYQu1bPidX1jC8p2ZxMWb+eOYrozo2qpWh5dwF0IIW6plw2+tNVpT6z6v\nEu5CCFEXrNTwu7ok3IUQoq79ouG3D/SeVKOG31WRcBdCCHuptOH3IOPhqGo2/L6R6oZ7/VjDUggh\nHIlSYIqCCZ/Bs4dg5F/gUjas+A283cW4GWtj1Qp3pVS0UuqwUuqYUurFm2w3QSmllVJV/q0ihBBO\noYkfRD0Jj++AaauMtoDV6BRlqZu3KAGUUq7Ah8BIIBNIVEqt1lofuG47b+ApYJstBiqEEA2ai4sR\n7O2H1s3hqrHNQOCY1jpVa10ELALGVbLdX4C3gAIrjk8IIUQtVCfcA4GMCq8zy9+7RinVD2intf7q\nZjtSSs1QSiUppZKys7NrPFghhBDVY/ENVaWUC/AO8FxV22qt52itw7TWYQEBAZYeWgghxA1UJ9yz\ngHYVXgeVv3eVN9AD2KSUMgPhwGq5qSqEEPZTnXBPBDoppUKVUh7AJGD11Q+11he01v5aa5PW2gRs\nBcZqrWUSuxBC2EmV4a61LgEeB74FDgJLtNb7lVKvK6XG2nqAQgghaq7KqZAAWuu1wNrr3nv1BtsO\ntXxYQgghLCFPqAohhAOy29oySqlsIK2KzfyBnDoYTn0j5+1cnPW8wXnP3ZLzDtFaVznd0G7hXh1K\nqaTqLJDjaOS8nYuznjc477nXxXlLWUYIIRyQhLsQQjig+h7uc+w9ADuR83Yuznre4LznbvPzrtc1\ndyGEELVT36/chRBC1EK9DffqNghp6JRSc5VSZ5RSyRXe81VKfaeUOlr+ewt7jtEWlFLtlFIblVIH\nlFL7lVJPlb/v0OeulPJUSm1XSu0pP+/Xyt8PVUptK/95X1y+1IfDUUq5KqV2KaXWlL92+PNWSpmV\nUvuUUruVUknl79n857xehnuFBiF3AN2AyUop63SXrX9igejr3nsR+F5r3Qn4vvy1oykBntNad8NY\nbO735f+NHf3cC4HhWuveQB8gWikVjtEL4R9a647AOeARO47Rlp7CWMbkKmc572Fa6z4Vpj/a/Oe8\nXoY71W8Q0uBprTcDZ697exwQV/51HHBPnQ6qDmitT2qtd5Z/fRHjf/hAHPzctSG//KV7+S8NDAeu\nNtZ0uPMGUEoFAXcCn5W/VjjBed+AzX/O62u4V9kgxMG10lqfLP/6FNDKnoOxNaWUCeiL0aLR4c+9\nvDSxGzgDfAekAOfLF+kDx/15fxd4Higrf+2Hc5y3BtYppXYopWaUv2fzn/NqLRwm7EdrrZVSDjul\nSSnVFFgGPK21zjMu5gyOeu5a61Kgj1KqObAC6GLnIdmcUuou4IzWeodSaqi9x1PHbtVaZymlWgLf\nKaUOVfzQVj/n9fXKvaoGIY7utFKqDUD572fsPB6bUEq5YwT7Aq318vK3neLcAbTW54GNQATQXCl1\n9WLLEX/eo4Cx5Q19FmGUY97D8c8brXVW+e9nMP4yH0gd/JzX13C/aYMQJ7AamF7+9XRglR3HYhPl\n9dZ/AQe11u9U+Mihz10pFVB+xY5SqjEwEuN+w0bgvvLNHO68tdYvaa2Dyhv6TAI2aK0fxMHPWynV\nRCnlffVrYBSQTB38nNfbh5iUUmMwanSuwFyt9Rt2HpJNKKUWAkMxVok7DfwZWAksAYIxVs6cqLW+\n/qZrg6aUuhX4EdjHf2uwf8SouzvsuSulemHcQHPFuLhaorV+XSnVHuOK1hfYBUzRWhfab6S2U16W\n+YPW+i5HP+/y81tR/tIN+FJr/YZSyg8b/5zX23AXQghRe/W1LCOEEMICEu5CCOGAJNyFEMIBSbgL\nIYQDknAXQggHJOEuhBAOSMJdCCEckIS7EEI4oP8HJhkLCuUywBoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117c6be80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "n_neighbors = [1, 3, 5, 10, 20, 50]\n",
    "train_errors, test_errors = validation_curve(KNeighborsRegressor(), X, y, param_name=\"n_neighbors\",\n",
    "                                             param_range=n_neighbors, cv=cv)\n",
    "plt.plot(n_neighbors, train_errors.mean(axis=1), label=\"train error\")\n",
    "plt.plot(n_neighbors, test_errors.mean(axis=1), label=\"test error\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that many neighbors mean a \"smooth\" or \"simple\" model, so the plot is the mirror image of the diagram above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If multiple parameters are important, like the parameters ``C`` and ``gamma`` in an ``SVM`` (more about that later), all possible combinations are tried:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.001000, gamma: 0.001000, average score: -0.084682\n",
      "C: 0.001000, gamma: 0.010000, average score: -0.016264\n",
      "C: 0.001000, gamma: 0.100000, average score: -0.017252\n",
      "C: 0.001000, gamma: 1.000000, average score: -0.081084\n",
      "C: 0.010000, gamma: 0.001000, average score: -0.041932\n",
      "C: 0.010000, gamma: 0.010000, average score: -0.106748\n",
      "C: 0.010000, gamma: 0.100000, average score: -0.017987\n",
      "C: 0.010000, gamma: 1.000000, average score: 0.017794\n",
      "C: 0.100000, gamma: 0.001000, average score: -0.041994\n",
      "C: 0.100000, gamma: 0.010000, average score: 0.181275\n",
      "C: 0.100000, gamma: 0.100000, average score: 0.469682\n",
      "C: 0.100000, gamma: 1.000000, average score: 0.409074\n",
      "C: 1.000000, gamma: 0.001000, average score: 0.087547\n",
      "C: 1.000000, gamma: 0.010000, average score: 0.585938\n",
      "C: 1.000000, gamma: 0.100000, average score: 0.662742\n",
      "C: 1.000000, gamma: 1.000000, average score: 0.674001\n",
      "C: 10.000000, gamma: 0.001000, average score: 0.590851\n",
      "C: 10.000000, gamma: 0.010000, average score: 0.581733\n",
      "C: 10.000000, gamma: 0.100000, average score: 0.643998\n",
      "C: 10.000000, gamma: 1.000000, average score: 0.774165\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# each parameter setting do cross-validation:\n",
    "for C in [0.001, 0.01, 0.1, 1, 10]:\n",
    "    for gamma in [0.001, 0.01, 0.1, 1]:\n",
    "        scores = cross_val_score(SVR(C=C, gamma=gamma), X, y, cv=cv)\n",
    "        print(\"C: %f, gamma: %f, average score: %f\" % (C, gamma, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is such a very common pattern, there is a built-in class for this in scikit-learn, ``GridSearchCV``. ``GridSearchCV`` takes a dictionary that describes the parameters that should be tried and a model to train.\n",
    "\n",
    "The grid of parameters is defined as a dictionary, where the keys are the parameters and the values are the settings to be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv, verbose=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the great things about GridSearchCV is that it is a *meta-estimator*. It takes an estimator like SVR above, and creates a new estimator, that behaves exactly the same - in this case, like a regressor.\n",
    "So we can call ``fit`` on it, to train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.058607, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.380923, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.104976, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ............. C=0.001, gamma=0.01, score=-0.055835, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ............. C=0.001, gamma=0.01, score=-0.377579, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ............. C=0.001, gamma=0.01, score=-0.102895, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .............. C=0.001, gamma=0.1, score=-0.043966, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .............. C=0.001, gamma=0.1, score=-0.365444, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .............. C=0.001, gamma=0.1, score=-0.093952, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................ C=0.001, gamma=1, score=-0.046497, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................ C=0.001, gamma=1, score=-0.370206, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................ C=0.001, gamma=1, score=-0.095600, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ............. C=0.01, gamma=0.001, score=-0.055543, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ............. C=0.01, gamma=0.001, score=-0.377178, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ............. C=0.01, gamma=0.001, score=-0.102678, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .............. C=0.01, gamma=0.01, score=-0.028158, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .............. C=0.01, gamma=0.01, score=-0.345457, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .............. C=0.01, gamma=0.01, score=-0.085711, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ................ C=0.01, gamma=0.1, score=0.070226, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ............... C=0.01, gamma=0.1, score=-0.259725, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ............... C=0.01, gamma=0.1, score=-0.013115, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] .................. C=0.01, gamma=1, score=0.058388, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ................. C=0.01, gamma=1, score=-0.273301, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ................. C=0.01, gamma=1, score=-0.032551, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] .............. C=0.1, gamma=0.001, score=-0.025310, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] .............. C=0.1, gamma=0.001, score=-0.343071, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] .............. C=0.1, gamma=0.001, score=-0.084344, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................ C=0.1, gamma=0.01, score=0.165773, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ............... C=0.1, gamma=0.01, score=-0.114345, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................ C=0.1, gamma=0.01, score=0.050818, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.556955, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.302134, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.396162, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.520439, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.219269, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.300676, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................. C=1, gamma=0.001, score=0.173736, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=1, gamma=0.001, score=-0.107583, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................. C=1, gamma=0.001, score=0.058236, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.640075, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.322109, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.534226, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.730909, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.472972, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.650330, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................... C=1, gamma=1, score=0.775976, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................... C=1, gamma=1, score=0.518687, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................... C=1, gamma=1, score=0.699567, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.633819, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.346238, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.538610, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................. C=10, gamma=0.01, score=0.703336, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................. C=10, gamma=0.01, score=0.407782, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................. C=10, gamma=0.01, score=0.572978, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.713049, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.463616, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.663887, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.782463, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.600560, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.787610, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=None, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What ``fit`` does is a bit more involved then what we did above. First, it runs the same loop with cross-validation, to find the best parameter combination.\n",
    "Once it has the best combination, it runs fit again on all data passed to fit (without cross-validation), to built a single new model using the best parameter setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, as with all models, we can use ``predict`` or ``score``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.79762875, -1.74054091, -1.71412904, -1.72272347, -1.76880247,\n",
       "       -1.8527208 , -1.97255382, -2.12407501, -2.30087676, -2.49463429,\n",
       "       -2.695503  , -2.89262935, -3.07474705, -3.23082299, -3.35071314,\n",
       "       -3.42578612, -3.44947391, -3.41771237, -3.32924127, -3.18574205,\n",
       "       -2.9918017 , -2.75470244, -2.48404785, -2.19124658, -1.88888388,\n",
       "       -1.59001819, -1.30744475, -1.05297034, -0.8367425 , -0.66667333,\n",
       "       -0.54799235, -0.4829551 , -0.4707249 , -0.50743515, -0.58642852,\n",
       "       -0.69865919, -0.83323456, -0.97806438, -1.12057877, -1.24847261,\n",
       "       -1.35043139, -1.41679516, -1.44012026, -1.41560488, -1.3413525 ,\n",
       "       -1.21845724, -1.05090633, -0.84530623, -0.61045003, -0.35675398,\n",
       "       -0.09559933,  0.16137852,  0.40300817,  0.61926205,  0.80185531,\n",
       "        0.94472644,  1.04437082,  1.10000798,  1.11357463,  1.08954695,\n",
       "        1.03460678,  0.95717608,  0.86685224,  0.7737823 ,  0.68801751,\n",
       "        0.61888941,  0.57444669,  0.56098656,  0.58270777,  0.64150352,\n",
       "        0.73690334,  0.86616306,  1.02449275,  1.20540425,  1.40115266,\n",
       "        1.60324152,  1.80295801,  1.99190412,  2.16249073,  2.3083654 ,\n",
       "        2.42474939,  2.50866621,  2.55905134,  2.57674055,  2.56434191,\n",
       "        2.52600389,  2.46709789,  2.39383845,  2.31286721,  2.23082834,\n",
       "        2.15396216,  2.0877418 ,  2.03657355,  2.00357681,  1.99045342,\n",
       "        1.99745004,  2.02341108,  2.06591373,  2.12147209,  2.18579347])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You can inspect the best parameters found by ``GridSearchCV`` in the ``best_params_`` attribute, and the best score in the ``best_score_`` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.724133314965\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a problem with using this score for evaluation, however. You might be making what is called a multiple hypothesis testing error. If you try very many parameter settings, some of them will work better just by chance, and the score that you obtained might not reflect how your model would perform on new unseen data.\n",
    "Therefore, it is good to split off a separate test-set before performing grid-search. This pattern can be seen as a training-validation-test split, and is common in machine learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/grid_search_cross_validation.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this very easily by splitting of some test data using ``train_test_split``, training ``GridSearchCV`` on the training set, and applying the ``score`` method to the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the parameters that were selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some practitioners go for an easier scheme, splitting the data simply into three parts, training, validation and testing. This is a possible alternative if your training set is very large, or it is infeasible to train many models using cross-validation because training a model takes very long.\n",
    "You can do this with scikit-learn for example by splitting of a test-set and then applying GridSearchCV with ShuffleSplit cross-validation with a single iteration:\n",
    "\n",
    "<img src=\"figures/train_validation_test2.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.002743, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] .............. C=0.001, gamma=0.01, score=0.000140, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] ............... C=0.001, gamma=0.1, score=0.011055, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................. C=0.001, gamma=1, score=0.006662, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] .............. C=0.01, gamma=0.001, score=0.000482, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] ............... C=0.01, gamma=0.01, score=0.028750, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ................ C=0.01, gamma=0.1, score=0.117008, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] .................. C=0.01, gamma=1, score=0.084841, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ............... C=0.1, gamma=0.001, score=0.032062, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................ C=0.1, gamma=0.01, score=0.254770, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.454768, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.414112, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................. C=1, gamma=0.001, score=0.276339, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.335464, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.038559, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................... C=1, gamma=1, score=0.266656, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.333921, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................ C=10, gamma=0.01, score=-0.056658, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.035099, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.278241, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.48420143290288065"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "single_split_cv = ShuffleSplit(n_splits=1)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=single_split_cv, verbose=3)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much faster, but might result in worse hyperparameters and therefore worse results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(SVR(), param_grid=param_grid)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "Apply grid-search to find the best setting for the number of neighbors in ``KNeighborsClassifier``, and apply it to the digits dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    4.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 1}\n",
      "0.985152190052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99111111111111116"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "param_grid = {'n_neighbors': range(1, 5)}\n",
    "\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid, cv=5, verbose=1)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .................... n_neighbors=1, score=0.970803, total=   0.4s\n",
      "[CV] n_neighbors=1 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... n_neighbors=1, score=0.988930, total=   0.4s\n",
      "[CV] n_neighbors=1 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... n_neighbors=1, score=0.988930, total=   0.3s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .................... n_neighbors=1, score=0.988764, total=   0.3s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .................... n_neighbors=1, score=0.988636, total=   0.2s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .................... n_neighbors=3, score=0.981752, total=   0.1s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .................... n_neighbors=3, score=0.988930, total=   0.1s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .................... n_neighbors=3, score=0.985240, total=   0.1s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .................... n_neighbors=3, score=0.985019, total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .................... n_neighbors=3, score=0.984848, total=   0.1s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .................... n_neighbors=5, score=0.985401, total=   0.1s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .................... n_neighbors=5, score=0.996310, total=   0.1s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .................... n_neighbors=5, score=0.974170, total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .................... n_neighbors=5, score=0.985019, total=   0.1s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .................... n_neighbors=5, score=0.984848, total=   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ................... n_neighbors=10, score=0.978102, total=   0.1s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ................... n_neighbors=10, score=0.981550, total=   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ................... n_neighbors=10, score=0.977860, total=   0.1s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ................... n_neighbors=10, score=0.981273, total=   0.1s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ................... n_neighbors=10, score=0.984848, total=   0.1s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ................... n_neighbors=50, score=0.927007, total=   0.1s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ................... n_neighbors=50, score=0.929889, total=   0.1s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ................... n_neighbors=50, score=0.952030, total=   0.1s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ................... n_neighbors=50, score=0.921348, total=   0.1s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ................... n_neighbors=50, score=0.958333, total=   0.0s\n",
      "Score on test set: 0.991111\n",
      "Best parameters: {'n_neighbors': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    9.0s finished\n"
     ]
    }
   ],
   "source": [
    "# %load solutions/14_grid_search.py\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "digits = load_digits()\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, random_state=0)\n",
    "\n",
    "param_grid = {'n_neighbors': [1, 3, 5, 10, 50]}\n",
    "gs = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid, cv=5, verbose=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(\"Score on test set: %f\" % gs.score(X_test, y_test))\n",
    "print(\"Best parameters: %s\" % gs.best_params_)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "TFG",
   "language": "python",
   "name": "tfg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
